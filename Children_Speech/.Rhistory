rm(list=ls(all=TRUE))
# Load the mclust library
library(mclust)
# Save USArrests data in to data varibale
rm(list=ls(all=T))
setwd("C:/Users/sid/Desktop/INSOFE/Lecture notes/TextMining/Day3/20170204_Batch22_CSE7306c_Lab03_TM_R_Python")
library(tm)              # Framework for text mining.
library(dplyr)           # Data wrangling, pipe operator %>%().
library(magrittr)
library(ggplot2)
library(RColorBrewer)    # Generate palette of colours for plots.
library(wordcloud)
cname <- file.path(getwd(), "corpus", "txt")
getwd(
getwd()
>
;
getwd()
setwd("C:/Users/sid/Desktop/INSOFE/Lecture notes/TextMining/Day1")
cname <- file.path(getwd(), "corpus", "txt")
cname
cname
dir(cname)
docs <- Corpus(DirSource(cname))
class(docs)
class(docs[[1]])
summary(docs)
inspect(docs)
writeLines(as.character(docs[[1]]))
getTransformations()
docs <- tm_map(docs, toSpace, "/")
toSpace <- content_transformer(function(x, pattern) gsub(pattern, " ", x))
docs <- tm_map(docs, toSpace, "/")
docs <- tm_map(docs, toSpace, "@")
docs <- tm_map(docs, toSpace, "\\|")
docs <- tm_map(docs, content_transformer(tolower))
viewDocs(docs, 16)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeWords, stopwords("english"))
docs <- tm_map(docs, stripWhitespace)
toString <- content_transformer(function(x, from, to) gsub(from, to, x))
docs <- tm_map(docs, toString, "america", "USA")
docs <- tm_map(docs, stemDocument)
dtm <- DocumentTermMatrix(docs)
dtm
tdm <- TermDocumentMatrix(docs)
tdm
rm(list=ls(all=T))
setwd("C:/Users/sid/Desktop/INSOFE/Lecture notes/TextMining/Day1")
library(tm)              # Framework for text mining.
library(dplyr)           # Data wrangling, pipe operator %>%().
library(magrittr)
library(ggplot2)
library(RColorBrewer)    # Generate palette of colours for plots.
library(wordcloud)
## location of text documents
cname <- file.path(getwd(), "corpus", "txt")
cname
dir(cname)
docs <- Corpus(DirSource(cname))
class(docs)
class(docs[[1]])
summary(docs)
inspect(docs)
# A character representation of a document is available via as.character()
writeLines(as.character(docs[[1]]))
viewDocs <- function(d, n) {d %>% extract2(n) %>% as.character() %>% writeLines()}
viewDocs(docs, 16)
## ------------------------------------------------------------------------
getTransformations()
#[1] "removeNumbers"     "removePunctuation" "removeWords"
#[4] "stemDocument"      "stripWhitespace"
## ----transformatioms-----------------------------------------------------
toSpace <- content_transformer(function(x, pattern) gsub(pattern, " ", x))
docs <- tm_map(docs, toSpace, "/")
docs <- tm_map(docs, toSpace, "@")
docs <- tm_map(docs, toSpace, "\\|")
viewDocs(docs, 16)
setwd("C:/Users/sid/Desktop/Data_Science/Kaggle/Text_analytics/Children_Speech")
file_info=as_data_frame(read.csv("../guide_to_files.csv"))
file_info=as_data_frame(read.csv("guide_to_files.csv"))
View(file_info)
install.packages("tidyverse")
install.packages("tidyverse")
